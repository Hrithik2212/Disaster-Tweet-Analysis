{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Disaster_Tweet_Analysis.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOPXLi0Wq0YTGo0t3TYIFKo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hrithik2212/Disaster-Tweet-Analysis/blob/main/Disaster_Tweet_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Disaster Tweet Analysis "
      ],
      "metadata": {
        "id": "29fBmhQQSigc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx2OXnm6Sqqj",
        "outputId": "eabe19ea-6eaa-4e78-e0e8-a71939973d14"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=13bd64795eae51f84cb84d75fc13794d5ab46f3fb07956f00b3299ad6955994f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx_Dh79eybGn",
        "outputId": "aad337fb-2a78-4e1f-99e3-00dbd7a2bb10"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Aug  5 10:36:41 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as npp\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns "
      ],
      "metadata": {
        "id": "NduONPcaSuWN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWRZDTIzS_Jy",
        "outputId": "ba8beb3f-a4dc-425a-b5cf-0daed2ccdc9e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-05 10:36:42--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-05 10:36:42 (79.9 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "H58queRbTMjW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Wrangling \n",
        "#### Source - Kaggle"
      ],
      "metadata": {
        "id": "6Q9LoR-RSnIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data (same as from Kaggle)\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKGgXK90TMCI",
        "outputId": "81a11e52-b838-4d73-abe6-07a46356d8a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-05 10:36:44--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.193.128, 173.194.74.128, 173.194.192.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.193.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2022-08-05 10:36:44 (144 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzipping nlp_getting_started.zip gives the following 3 .csv files:\n",
        "\n",
        "* sample_submission.csv - an example of the file you'd submit to the Kaggle competition of your model's predictions.\n",
        "* train.csv - training samples of real and not real diaster Tweets.\n",
        "* test.csv - testing samples of real and not real diaster Tweets."
      ],
      "metadata": {
        "id": "9s2ot6EOTeIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration and Cleaning "
      ],
      "metadata": {
        "id": "FqdVfizHTruy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/test.csv\")\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zuLrjfGZTY2b",
        "outputId": "e9da54ec-a5df-483a-a420-0e2bf09b710e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c4bcc48-a222-4dab-add1-edeae814a7ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c4bcc48-a222-4dab-add1-edeae814a7ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c4bcc48-a222-4dab-add1-edeae814a7ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c4bcc48-a222-4dab-add1-edeae814a7ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle training dataframe\n",
        "train_df = train_df.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ptbqSIX7T1pG",
        "outputId": "c9f9d3aa-8a0a-42f1-bc59-58cbacb7c674"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1ff5e10-33b3-4c78-bab1-0bf8b2ae50be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1ff5e10-33b3-4c78-bab1-0bf8b2ae50be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c1ff5e10-33b3-4c78-bab1-0bf8b2ae50be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c1ff5e10-33b3-4c78-bab1-0bf8b2ae50be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 1 = Real Disaster Tweet\n",
        "* 0 = Not Real Disaster Tweet"
      ],
      "metadata": {
        "id": "sHVmPMaqUbze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = train_df.target.value_counts()\n",
        "m.plot(kind = 'barh')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "o9CD8z9dUEh-",
        "outputId": "1a5efdce-0ef4-4675-8f5d-52795a4622e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2c2a172410>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.isnull().sum()"
      ],
      "metadata": {
        "id": "bIrFIy5TUR7X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cf461e4-f0b2-40e2-eddb-4271fb0eddb0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id             0\n",
              "keyword       61\n",
              "location    2533\n",
              "text           0\n",
              "target         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing % of unique values in each col\n",
        "no_of_uni_values_columns=[]\n",
        "for col in train_df.columns:\n",
        "    no_of_uni_values_columns.append(len(train_df[col].unique())/len(train_df))\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.bar(train_df.columns,no_of_uni_values_columns)\n",
        "plt.title(\"% of unique values in each col\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "kw310H0ry8Y4",
        "outputId": "781b91c6-69f7-4dac-de0b-32f5e29ddd45"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '% of unique values in each col')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total training samples: {len(train_df)}\")\n",
        "print(f\"Total test samples: {len(test_df)}\")\n",
        "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FM-ht_izLmo",
        "outputId": "b5b462ba-ddc9-4cc5-df6e-077e4a8605a0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training samples: 7613\n",
            "Total test samples: 3263\n",
            "Total samples: 10876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RvHHLAz0YYy",
        "outputId": "2e1ef6b5-1173-4114-b3dc-08135e8bf0be"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@adorableappple No reported flooding po in the area. Ten-4. #mmda\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@DelDryden If I press on the twitch will my head explode?\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Earthquake drill ??????\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Mumbai24x7 Helping Hand: In Mumbai 2 TTEs take charge of helpline to calm anxious relatives - The Ind... http://t.co/tUARYIJpqU #Mumbai\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "A [small] flood with bigåÊconsequences https://t.co/CVPdVHxd1R http://t.co/FDMXP4FcMo\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering (Text to Numbers)"
      ],
      "metadata": {
        "id": "Qa4NN8oe1gi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In NLP, there are two main concepts for turning text into numbers:\n",
        "\n",
        "* Tokenization - A straight mapping from word or character or sub-word to a numerical value. There are three main levels of tokenization:\n",
        "\n",
        "1. Using word-level tokenization with the sentence \"I love TensorFlow\" might result in \"I\" being 0, \"love\" being 1 and \"TensorFlow\" being\n",
        "2. In this case, every word in a sequence considered a single token.\n",
        "Character-level tokenization, such as converting the letters A-Z to values 1-26. In this case, every character in a sequence considered a single token.\n",
        "3. Sub-word tokenization is in between word-level and character-level tokenization. It involves breaking invidual words into smaller parts and then converting those smaller parts into numbers. For example, \"my favourite food is pineapple pizza\" might become \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After doing this, these sub-words would then be mapped to a numerical value. In this case, every word could be considered multiple tokens.\n",
        "\n",
        "* Embeddings - An embedding is a representation of natural language which can be learned. Representation comes in the form of a feature vector. For example, the word \"dance\" could be represented by the 5-dimensional vector [-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]. It's important to note here, the size of the feature vector is tuneable. There are two ways to use embeddings:\n",
        "1. Create your own embedding - Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as tf.keras.layers.Embedding) and an embedding representation will be learned during model training.\n",
        "2. Reuse a pre-learned embedding - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task.\n",
        "\n",
        "If you're looking for pre-trained word embeddings, Word2vec embeddings, GloVe embeddings and many of the options available on TensorFlow Hub are great places to start."
      ],
      "metadata": {
        "id": "tVoocLEk2ELH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stop Words Removal"
      ],
      "metadata": {
        "id": "ppihraZV9yJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "train_df['text'] = tf.strings.regex_replace(train_df['text'], r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*',\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nufbzauq9ysl",
        "outputId": "4b391258-7790-40cb-ca06-f1abb847bbc5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['text'][:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dcsfa8dw9y1s",
        "outputId": "90c5aac1-60ea-4785-9132-dee0814ea744"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2644    b'So new weapon cause un-imaginable destruction.'\n",
              "2227    b'The f$&amp;@ing things I #GISHWHES Just got ...\n",
              "5448    b'DT @georgegalloway: RT @Galloway4Mayor: \\xc2...\n",
              "132     b'Aftershock back school kick great. I want th...\n",
              "6845    b'response trauma Children Addicts develop def...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df[\"text\"].to_numpy(),\n",
        "                                                                            train_df[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=42)"
      ],
      "metadata": {
        "id": "FnQVR354_YqI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_9T5HeV_eAd",
        "outputId": "4b2ef18a-2152-4708-cdf3-8a124bbade78"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:10], train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC88Xl21_gE-",
        "outputId": "bb6aa0e5-20fd-4735-b991-cdeb8dea13b3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([b'@mogacola @zamtriossu screamed hitting tweet',\n",
              "        b'Imagine getting flattened Kurt Zouma',\n",
              "        b'@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        b\"@shakjn @C7 @Magnums im shaking fear 'gonna hack planet\",\n",
              "        b'Somehow find I collide http://.co/Ee8RpOahPk',\n",
              "        b'@EvaHanderek @MarleyKnysh great times bus driver held us hostage mall parking lot lmfao',\n",
              "        b'destroy free fandom honestly',\n",
              "        b'Weapons stolen National Guard Armory New Albany still missing #Gunsense http://.co/lKNU8902JE',\n",
              "        b'@wfaaweather Pete heat wave pass? Is really going mid month? Frisco Boy Scouts canoe trip Okla.',\n",
              "        b'Patient-reported outcomes long-term survivors metastatic colorectal cancer - British Journal Surgery http://.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization \n",
        "The TextVectorization layer takes the following parameters:\n",
        "\n",
        "* **_max_tokens_** - The maximum number of words in your vocabulary (e.g. 20000 or the number of unique words in your text), includes a value for OOV (out of vocabulary) tokens.\n",
        "* **_standardize_** - Method for standardizing text. Default is \"lower_and_strip_punctuation\" which lowers text and removes all punctuation marks.\n",
        "* **_split_** - How to split text, default is \"whitespace\" which splits on spaces.\n",
        "* **_ngrams_** - How many words to contain per token split, for example,ngrams=2 splits tokens into continuous sequences of 2.\n",
        "* **_output_mode_** - How to output tokens, can be \"int\" (integer mapping), \"binary\" (one-hot encoding), \"count\" or \"tf-idf\". See documentation for more.\n",
        "* **_output_sequence_length_** - Length of tokenized sequence to output. For example, if output_sequence_length=150, all tokenized sequences will be 150 tokens long.\n",
        "* **_pad_to_max_tokens_** - Defaults to False, if True, the output feature axis will be padded to max_tokens even if the number of unique tokens in the vocabulary is less than max_tokens. Only valid in certain modes, see docs for more."
      ],
      "metadata": {
        "id": "II1NdOsq3PFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find average number of tokens (words) in training Tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMQRGJHR456A",
        "outputId": "6d4a3135-9e3b-41df-a79d-02aa5778ca3e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The verage Tweet size is 11 and does we will do 20 "
      ],
      "metadata": {
        "id": "qJffKI0w5Emc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens = 20000,\n",
        "                                   output_mode= 'int' ,\n",
        "                                   output_sequence_length=25,\n",
        "                                   )"
      ],
      "metadata": {
        "id": "spNks1cP1XKc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer"
      ],
      "metadata": {
        "id": "8AqQRwC15foC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "WvpRjaQH9T5U"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tweet = \"Last week the amazon forest was on fire\"\n",
        "text_vectorizer([sample_tweet])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSDjSAgF5m-B",
        "outputId": "b863e5d6-e597-444e-b70f-09f296f9cc19"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 25), dtype=int64, numpy=\n",
              "array([[  80,  481,    3, 1245,  124,  788,  131,    7,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\") \n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk6dcdb15x9D",
        "outputId": "b429f723-58a9-4f05-b9c2-bb5d88512c4e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 20000\n",
            "Top 5 most common words: ['', '[UNK]', 'i', 'the', 'like']\n",
            "Bottom 5 least common words: ['berlatsky', 'beram0s', 'berahino', 'benzema', 'bentley']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Embedded Layer \n",
        "\n",
        "The powerful thing about an embedding is it can be learned during training. This means rather than just being static (e.g. 1 = I, 2 = love, 3 = TensorFlow), a word's numeric representation can be improved as a model goes through data samples.\n",
        "\n",
        "We can see what an embedding of a word looks like by using the tf.keras.layers.Embedding layer.\n",
        "\n",
        "The main parameters we're concerned about here are:\n",
        "\n",
        "* **input_dim** - The size of the vocabulary (e.g. len(text_vectorizer.get_vocabulary()).\n",
        "* **output_dim** - The size of the output embedding vector, for example, a value of 100 outputs a feature vector of size 100 for each word.\n",
        "* **embeddings_initializer** - How to initialize the embeddings matrix, default is \"uniform\" which randomly initalizes embedding matrix with uniform distribution. This can be changed for using pre-learned embeddings.\n",
        "* **input_length** - Length of sequences being passed to embedding layer."
      ],
      "metadata": {
        "id": "TF_LNRmm_3rB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=20000, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=25, # how long is each input\n",
        "                             name=\"embedding_1\") \n",
        "\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYTxdbRm9lW1",
        "outputId": "b067a6fb-b173-42aa-abb5-514e40932c42"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f2ba86728d0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAvPNcSiAnJV",
        "outputId": "49495f16-26fa-4f7f-fb12-45526911e6d8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "b\"nside Dragon'belly. Or ice cave volcano Kamchatka | Photography \\xc3\\xa5\\xc2\\xa9Daniel Korzhonov\\nhttp://.co/8T36HWgoqd\"      \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 25, 128), dtype=float32, numpy=\n",
              "array([[[-0.0279819 , -0.00807878,  0.04520786, ...,  0.00023776,\n",
              "          0.01473805,  0.03766337],\n",
              "        [ 0.03231491,  0.03477775, -0.04285641, ..., -0.0138584 ,\n",
              "         -0.03291193, -0.03539581],\n",
              "        [-0.00579132, -0.04821959,  0.04538285, ..., -0.03094784,\n",
              "         -0.04862892,  0.01227155],\n",
              "        ...,\n",
              "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
              "          0.00912381, -0.00024097],\n",
              "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
              "          0.00912381, -0.00024097],\n",
              "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
              "          0.00912381, -0.00024097]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building and Training \n",
        "\n",
        "* Model 0: Naive Bayes (baseline)\n",
        "* Model 1: Feed-forward neural network (dense model)\n",
        "* Model 2: LSTM model\n",
        "* Model 3: GRU model\n",
        "* Model 4: Bidirectional-LSTM model\n",
        "* Model 5: 1D Convolutional Neural Network\n",
        "* Model 6: TensorFlow Hub Pretrained Feature Extractor\n",
        "* Model 7: Same as model 6 with 10% of training data"
      ],
      "metadata": {
        "id": "lEhYSN8aBQ9W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 0 : Naive Bayes"
      ],
      "metadata": {
        "id": "a3FPFJenliuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "Model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"Bayes_Classifier\", MultinomialNB()) # model the text\n",
        "])"
      ],
      "metadata": {
        "id": "KlNWfNrrBAWY"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model_0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZbW1nirlx6P",
        "outputId": "0ebef058-2eae-4287-fddc-bd3086316830"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                ('Bayes_Classifier', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_0.fit(train_sentences,train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86KCTQ7jl0sa",
        "outputId": "8633779b-a73d-4d6f-c5fa-0ff48c1e9a72"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                ('Bayes_Classifier', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_0_score = Model_0.score(val_sentences, val_labels)\n",
        "print(f\"Naive Bayes model achieves an accuracy of: {Model_0_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo4-VJQqmGQ0",
        "outputId": "75711333-c063-4e23-9a01-a47d17a1f5c9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes model achieves an accuracy of: 80.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1 : Feed Forward Neural Network with Two Hidden Layers"
      ],
      "metadata": {
        "id": "acICl9KNmea-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models  import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop "
      ],
      "metadata": {
        "id": "F-T8WFvonLFR"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
        "dense1 = layers.Dense(128, activation=\"relu\",\n",
        "                      kernel_regularizer=tf.keras.regularizers.L1(0.01),\n",
        "                      activity_regularizer=tf.keras.regularizers.L2(0.01))(x) \n",
        "dropout = layers.Dropout(0.5)(dense1)\n",
        "outputs = layers.Dense(1,activation = 'sigmoid')(dropout) # create the output layer, want binary outputs so use sigmoid activation\n",
        "Model_1 = tf.keras.Model(inputs, outputs, name=\"FNN\") # construct the model\n",
        "Model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dnMxed_nRo4",
        "outputId": "e57a394b-0ff1-4b49-e8e7-bfbf50358601"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"FNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 25)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 25, 128)           2560000   \n",
            "                                                                 \n",
            " global_average_pooling1d_6   (None, 128)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,576,641\n",
            "Trainable params: 2,576,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "q3kGFJuFoB_7"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model_1_history = Model_1.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs =10,\n",
        "                              validation_data = (val_sentences ,val_labels),\n",
        "                              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvMYjAA-pFPN",
        "outputId": "9cbb842c-c625-4c93-d302-ce2ff0b93986"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "215/215 [==============================] - 2s 6ms/step - loss: 3.7179 - accuracy: 0.8505 - val_loss: 0.7547 - val_accuracy: 0.7178\n",
            "Epoch 2/10\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.6213 - accuracy: 0.9175 - val_loss: 0.7386 - val_accuracy: 0.7769\n",
            "Epoch 3/10\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.5256 - accuracy: 0.9467 - val_loss: 0.7038 - val_accuracy: 0.7769\n",
            "Epoch 4/10\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.4671 - accuracy: 0.9501 - val_loss: 0.6875 - val_accuracy: 0.7808\n",
            "Epoch 5/10\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.4275 - accuracy: 0.9561 - val_loss: 0.6721 - val_accuracy: 0.7795\n",
            "Epoch 6/10\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.3986 - accuracy: 0.9613 - val_loss: 0.6574 - val_accuracy: 0.7822\n",
            "Epoch 7/10\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.3726 - accuracy: 0.9635 - val_loss: 0.6583 - val_accuracy: 0.7822\n",
            "Epoch 8/10\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.3499 - accuracy: 0.9692 - val_loss: 0.6482 - val_accuracy: 0.7835\n",
            "Epoch 9/10\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.3371 - accuracy: 0.9667 - val_loss: 0.6470 - val_accuracy: 0.7874\n",
            "Epoch 10/10\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.3188 - accuracy: 0.9701 - val_loss: 0.6408 - val_accuracy: 0.7861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Model without Dropout(Overfitting) - Train Set 99 % , Test Set 71 % \n",
        "* Model with Dropout and with L1 L2 reg - Train Set 97 % , Test Set 78 % "
      ],
      "metadata": {
        "id": "oYuc8ylIrHlH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2 : Simple RNN "
      ],
      "metadata": {
        "id": "uQhBU9twqHP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import initializers"
      ],
      "metadata": {
        "id": "I3J4nY0ctr8r"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model_2 = Sequential()\n",
        "Model_2.add(Input(shape=(1,),dtype='string'))\n",
        "Model_2.add(text_vectorizer)\n",
        "Model_2.add(embedding)\n",
        "Model_2.add(tf.keras.layers.SimpleRNN(24,\n",
        "                                      kernel_initializer=initializers.RandomNormal(stddev=0.001),\n",
        "                                      recurrent_initializer=initializers.Identity(gain=1.0)))\n",
        "Model_2.add(layers.Dropout(0.8))\n",
        "Model_2.add(Dense(24,activation='relu', \n",
        "                  kernel_regularizer=tf.keras.regularizers.L1(0.2),\n",
        "                  activity_regularizer=tf.keras.regularizers.L2(0.1)))\n",
        "Model_2.add(Dense(1,activation ='sigmoid'))\n",
        "Model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXl9ZaJoplpN",
        "outputId": "a2bba458-0465-4ce9-8214-09e578d39af2"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, 25)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     multiple                  2560000   \n",
            "                                                                 \n",
            " simple_rnn_15 (SimpleRNN)   (None, 24)                3672      \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 24)                0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 24)                600       \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,564,297\n",
            "Trainable params: 2,564,297\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_2.compile(loss = 'binary_crossentropy',\n",
        "                optimizer = Adam(),\n",
        "                metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "sRngqrjxpPLF"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model_2_history = Model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs =5,\n",
        "                              validation_data = (val_sentences ,val_labels),\n",
        "                              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXmvjFQludtA",
        "outputId": "407afa9b-d608-44ec-ffe1-0bb3eff72272"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 29ms/step - loss: 10.8848 - accuracy: 0.9675 - val_loss: 3.6688 - val_accuracy: 0.7205\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 6s 28ms/step - loss: 1.2946 - accuracy: 0.9215 - val_loss: 0.7771 - val_accuracy: 0.7218\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 6s 28ms/step - loss: 0.6422 - accuracy: 0.9564 - val_loss: 0.7988 - val_accuracy: 0.7244\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 6s 28ms/step - loss: 0.6006 - accuracy: 0.9740 - val_loss: 0.7957 - val_accuracy: 0.7349\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 6s 27ms/step - loss: 0.5493 - accuracy: 0.9853 - val_loss: 0.8275 - val_accuracy: 0.7231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3 : LSTM"
      ],
      "metadata": {
        "id": "q5uA0e9ty075"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers\n",
        "Model_3 = Sequential()\n",
        "Model_3.add(Input(shape=(1,),dtype='string'))\n",
        "Model_3.add(text_vectorizer)\n",
        "Model_3.add(embedding)\n",
        "Model_3.add(layers.LSTM(64))\n",
        "Model_3.add(Dense(64,activation ='relu',\n",
        "            kernel_regularizer = regularizers.L1(0.1),\n",
        "            activity_regularizer= regularizers.L2(0.01)))\n",
        "Model_3.add(Dropout(0.8))\n",
        "Model_3.add(Dense(1,activation = 'sigmoid'))\n",
        "Model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtkjuA8Tu2fB",
        "outputId": "4d3ee2ee-79be-427e-c5fa-6f30713dda61"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, 25)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     multiple                  2560000   \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,613,633\n",
            "Trainable params: 2,613,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_3.compile(loss='binary_crossentropy',\n",
        "                optimizer = Adam(),\n",
        "                metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "E42IiaqDz1eR"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model_3_history = Model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs = 5 ,\n",
        "                              validation_data = (val_sentences,val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c11KHEKE0_ec",
        "outputId": "77de2675-5cd4-4e50-860b-09e3eb80c0ce"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 10ms/step - loss: 15.6499 - accuracy: 0.9388 - val_loss: 0.9188 - val_accuracy: 0.7572\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.6365 - accuracy: 0.9529 - val_loss: 0.8116 - val_accuracy: 0.7533\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.5748 - accuracy: 0.9591 - val_loss: 0.8305 - val_accuracy: 0.7612\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.5281 - accuracy: 0.9604 - val_loss: 0.8226 - val_accuracy: 0.7559\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.5208 - accuracy: 0.9534 - val_loss: 0.8528 - val_accuracy: 0.7572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4 : GRU Model"
      ],
      "metadata": {
        "id": "_Dv0HKif2eep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eaeQF4Ym1RNr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}